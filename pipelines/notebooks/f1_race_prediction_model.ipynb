{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb130a10",
   "metadata": {},
   "source": [
    "# F1 Race Prediction Model\n",
    "\n",
    "This notebook builds a machine learning model to predict F1 race results using the results.csv fact table and related CSV files. The final model will be saved as a .pkl file and wrapped in a FastAPI application.\n",
    "\n",
    "## Project Overview\n",
    "- **Data Source**: F1 CSV files (results.csv as fact table)\n",
    "- **Goal**: Predict race finishing positions\n",
    "- **Output**: Trained model (.pkl) + FastAPI application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7ede8",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and ML libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# API libraries\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01863983",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "Load the CSV files and explore the data structure. The `results.csv` is our fact table that connects to other dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file paths\n",
    "data_path = '../data/'\n",
    "\n",
    "# Load CSV files\n",
    "print(\"Loading F1 data...\")\n",
    "results_df = pd.read_csv(data_path + 'results.csv')\n",
    "races_df = pd.read_csv(data_path + 'races.csv')\n",
    "drivers_df = pd.read_csv(data_path + 'drivers.csv')\n",
    "constructors_df = pd.read_csv(data_path + 'constructors.csv')\n",
    "circuits_df = pd.read_csv(data_path + 'circuits.csv')\n",
    "qualifying_df = pd.read_csv(data_path + 'qualifying.csv')\n",
    "\n",
    "# Display basic info about the fact table (results)\n",
    "print(\"Results DataFrame Info:\")\n",
    "print(f\"Shape: {results_df.shape}\")\n",
    "print(f\"Columns: {list(results_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d84078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data quality and relationships\n",
    "print(\"Data Quality Check:\")\n",
    "print(f\"Results missing values: {results_df.isnull().sum().sum()}\")\n",
    "print(f\"Races missing values: {races_df.isnull().sum().sum()}\")\n",
    "print(f\"Drivers missing values: {drivers_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Check target variable distribution (position)\n",
    "print(\"\\nPosition distribution:\")\n",
    "print(results_df['position'].value_counts().sort_index().head(10))\n",
    "\n",
    "# Check for key relationships\n",
    "print(f\"\\nUnique races in results: {results_df['raceId'].nunique()}\")\n",
    "print(f\"Unique drivers in results: {results_df['driverId'].nunique()}\")\n",
    "print(f\"Unique constructors in results: {results_df['constructorId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64518618",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering\n",
    "\n",
    "Clean the data and create features that will help predict race positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2908f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and prepare the results data\n",
    "results_clean = results_df.copy()\n",
    "\n",
    "# Convert position to numeric, handle 'N' and '\\N' values\n",
    "results_clean['position'] = pd.to_numeric(results_clean['position'], errors='coerce')\n",
    "\n",
    "# Filter out rows where position is NaN (DNF, DSQ, etc.) for training\n",
    "# We want to predict finishing positions, not DNFs\n",
    "results_clean = results_clean.dropna(subset=['position'])\n",
    "\n",
    "# Convert grid position to numeric\n",
    "results_clean['grid'] = pd.to_numeric(results_clean['grid'], errors='coerce')\n",
    "\n",
    "# Handle missing grid positions (fill with max grid + 1, indicating back of grid)\n",
    "max_grid = results_clean['grid'].max()\n",
    "results_clean['grid'] = results_clean['grid'].fillna(max_grid + 1)\n",
    "\n",
    "print(f\"Cleaned results shape: {results_clean.shape}\")\n",
    "print(f\"Position range: {results_clean['position'].min()} to {results_clean['position'].max()}\")\n",
    "print(f\"Grid range: {results_clean['grid'].min()} to {results_clean['grid'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c88824",
   "metadata": {},
   "source": [
    "## 4. Merge Tables and Create Dataset\n",
    "\n",
    "Join the results table with other dimension tables to create a comprehensive dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge results with races to get race info\n",
    "dataset = results_clean.merge(races_df, on='raceId', how='left')\n",
    "\n",
    "# Merge with drivers to get driver info\n",
    "dataset = dataset.merge(drivers_df, on='driverId', how='left')\n",
    "\n",
    "# Merge with constructors to get constructor info\n",
    "dataset = dataset.merge(constructors_df, on='constructorId', how='left')\n",
    "\n",
    "# Merge with circuits to get circuit info\n",
    "dataset = dataset.merge(circuits_df, on='circuitId', how='left')\n",
    "\n",
    "# Add qualifying data (qualifying position as a feature)\n",
    "qualifying_clean = qualifying_df.copy()\n",
    "qualifying_clean['q1'] = pd.to_numeric(qualifying_clean['q1'], errors='coerce')\n",
    "qualifying_clean['q2'] = pd.to_numeric(qualifying_clean['q2'], errors='coerce')\n",
    "qualifying_clean['q3'] = pd.to_numeric(qualifying_clean['q3'], errors='coerce')\n",
    "\n",
    "# Create a best qualifying time feature\n",
    "def get_best_qualifying_time(row):\n",
    "    times = [row['q1'], row['q2'], row['q3']]\n",
    "    valid_times = [t for t in times if pd.notna(t)]\n",
    "    return min(valid_times) if valid_times else None\n",
    "\n",
    "qualifying_clean['best_qualifying_time'] = qualifying_clean.apply(get_best_qualifying_time, axis=1)\n",
    "\n",
    "# Merge qualifying data\n",
    "dataset = dataset.merge(\n",
    "    qualifying_clean[['raceId', 'driverId', 'position', 'best_qualifying_time']], \n",
    "    on=['raceId', 'driverId'], \n",
    "    how='left',\n",
    "    suffixes=('', '_qualifying')\n",
    ")\n",
    "\n",
    "print(f\"Final dataset shape: {dataset.shape}\")\n",
    "print(f\"Columns: {list(dataset.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb06c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering - create meaningful features for prediction\n",
    "# Select key features for the model\n",
    "feature_columns = [\n",
    "    'grid',  # Starting grid position\n",
    "    'driverId',  # Driver ID (will be encoded)\n",
    "    'constructorId',  # Constructor ID (will be encoded) \n",
    "    'circuitId',  # Circuit ID (will be encoded)\n",
    "    'year',  # Year of race\n",
    "    'round',  # Round number in season\n",
    "    'position_qualifying',  # Qualifying position\n",
    "    'best_qualifying_time'  # Best qualifying time\n",
    "]\n",
    "\n",
    "# Create the feature dataset\n",
    "ml_dataset = dataset[feature_columns + ['position']].copy()\n",
    "\n",
    "# Handle missing values\n",
    "ml_dataset['position_qualifying'] = ml_dataset['position_qualifying'].fillna(20)  # Back of grid\n",
    "ml_dataset['best_qualifying_time'] = ml_dataset['best_qualifying_time'].fillna(\n",
    "    ml_dataset['best_qualifying_time'].max()  # Slowest time for missing\n",
    ")\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "ml_dataset = ml_dataset.dropna()\n",
    "\n",
    "print(f\"ML dataset shape: {ml_dataset.shape}\")\n",
    "print(f\"Features: {feature_columns}\")\n",
    "print(f\"Target: position\")\n",
    "print(f\"\\nDataset info:\")\n",
    "ml_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88b3e1",
   "metadata": {},
   "source": [
    "## 5. Train-Test Split\n",
    "\n",
    "Split the dataset into training and testing sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb122738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = ml_dataset[feature_columns].copy()\n",
    "y = ml_dataset['position'].copy()\n",
    "\n",
    "# Encode categorical variables (IDs)\n",
    "encoders = {}\n",
    "categorical_features = ['driverId', 'constructorId', 'circuitId']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    encoder = LabelEncoder()\n",
    "    X[feature] = encoder.fit_transform(X[feature])\n",
    "    encoders[feature] = encoder\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training target distribution: min={y_train.min()}, max={y_train.max()}, mean={y_train.mean():.2f}\")\n",
    "print(f\"Test target distribution: min={y_test.min()}, max={y_test.max()}, mean={y_test.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb1996",
   "metadata": {},
   "source": [
    "## 6. Model Training and Evaluation\n",
    "\n",
    "Train multiple models and select the best performing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'model': model,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "    \n",
    "    print(f\"  Train MAE: {train_mae:.3f}, Test MAE: {test_mae:.3f}\")\n",
    "    print(f\"  Train RMSE: {train_rmse:.3f}, Test RMSE: {test_rmse:.3f}\")\n",
    "    print(f\"  Train R¬≤: {train_r2:.3f}, Test R¬≤: {test_r2:.3f}\")\n",
    "\n",
    "# Select best model based on test MAE\n",
    "best_model_name = min(model_results.keys(), key=lambda x: model_results[x]['test_mae'])\n",
    "best_model = model_results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nüèÜ Best model: {best_model_name}\")\n",
    "print(f\"Test MAE: {model_results[best_model_name]['test_mae']:.3f}\")\n",
    "print(f\"Test R¬≤: {model_results[best_model_name]['test_r2']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81a5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nüìä Feature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "    plt.title(f'{best_model_name} - Feature Importance')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec053a9",
   "metadata": {},
   "source": [
    "## 7. Save Model as Pickle File\n",
    "\n",
    "Save the trained model and encoders for use in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model package with everything needed for prediction\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'encoders': encoders,\n",
    "    'feature_columns': feature_columns,\n",
    "    'model_name': best_model_name,\n",
    "    'model_metrics': model_results[best_model_name]\n",
    "}\n",
    "\n",
    "# Save the model package\n",
    "model_path = '../models/f1_race_prediction_model.pkl'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {model_path}\")\n",
    "print(f\"Model type: {best_model_name}\")\n",
    "print(f\"Test MAE: {model_results[best_model_name]['test_mae']:.3f}\")\n",
    "print(f\"Features: {feature_columns}\")\n",
    "\n",
    "# Verify the saved model by loading it\n",
    "with open(model_path, 'rb') as f:\n",
    "    loaded_model_package = pickle.load(f)\n",
    "\n",
    "print(f\"\\n‚úÖ Model verification successful!\")\n",
    "print(f\"Loaded model type: {type(loaded_model_package['model'])}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
